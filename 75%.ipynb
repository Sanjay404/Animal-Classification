{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXlJTBiZ-oEO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#zip_ref = zipfile.ZipFile('drive/My Drive/Colab Notebooks/ALL DATA/smaller_animals.zip', 'r')\n",
    "#zip_ref.extractall(path='drive/My Drive/Colab Notebooks/ALL DATA/animals') # unzip file\n",
    "#zip_ref.close()\n",
    "\n",
    "#!unzip -q 'drive/My Drive/Colab Notebooks/ALL DATA/zips/smaller_animals.zip' -d 'drive/My Drive/Colab Notebooks/ALL DATA/animals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMjJ6B1hGqPT"
   },
   "outputs": [],
   "source": [
    "#!rm -rf '/content/drive/My Drive/Colab Notebooks/ALL DATA/__MACOSX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bOsgQrkG-sMN",
    "outputId": "e358608b-ea91-48a3-c8a2-201bb0e61cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] READ IN ZIP\n"
     ]
    }
   ],
   "source": [
    "#base_dir = \"drive/My Drive/Colab Notebooks/ALL DATA/animals\"\n",
    "base_dir = '/home/srikumar/Desktop/'\n",
    "#base_dir = \"/Users/sanjay/Desktop/CODE/Python/Animal-Classification/DATA\"\n",
    "class_names = ['cat', 'lynx', 'wolf', 'coyote', 'cheetah', 'jaguar', 'chimpanzee', 'orangutan', 'hamster', 'guinea pig']\n",
    "print('[DATA] READ IN ZIP')\n",
    "date_base = os.path.join(base_dir,'animals')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XxlxiEPV-wE7",
    "outputId": "e5a7ee83-e99c-4a86-ab68-35d1da864b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "import glob\n",
    "import shutil\n",
    "for folder in os.listdir(date_base):\n",
    "  print(folder)\n",
    "  if(folder =='.DS_Store'):\n",
    "    continue\n",
    "  if not(path.exists(os.path.join(date_base, folder,'sorted'))): #makes sorted folder \n",
    "    print('Made sorted in ', folder )\n",
    "    os.mkdir(os.path.join(date_base, folder,'sorted'))\n",
    "  #Splits up images into categorized directories\n",
    "  for image in os.listdir(os.path.join(date_base, folder)):\n",
    "    if not('_img_' in image):\n",
    "      continue\n",
    "    animal = image.split(\"_img_\")[0]\n",
    "    target_dir = os.path.join(date_base,folder,'sorted',animal)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    if not path.exists(os.path.join(target_dir, image)): #if image hasnt been copied over\n",
    "        shutil.copy(os.path.join(date_base,folder,image), os.path.join(target_dir,image))  \n",
    "print('done!') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42G9vwJndT2Q"
   },
   "source": [
    "# Keras ImageDataGenerator/Images as numpy array\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "aMKwbrybdVGf",
    "outputId": "edd151b9-b200-4a4a-d2d1-13a27d37872d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10993 images belonging to 10 classes.\n",
      "Found 44006 images belonging to 10 classes.\n",
      "running1\n",
      "finished running1\n",
      "running2\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import *\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(date_base, 'training', 'sorted'),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(date_base, 'testing', 'sorted'),\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "#Data in np arrays\n",
    "data = []\n",
    "labels = []\n",
    "print('running1')\n",
    "imagePaths = sorted(list(paths.list_images(date_base+'/training')))\n",
    "for imagePath in imagePaths:\n",
    "\t#load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\ttry:\n",
    "\t\timage = cv2.resize(image,(28,28))\n",
    "\t\timage = img_to_array(image)\n",
    "\t\tdata.append(image)\n",
    "\t\t# extract the class label from the image path and update the labels list\n",
    "\t\tlabel = imagePath.split(os.path.sep)[-1]\n",
    "\t\tlabels.append(label[0]) #strips the number label from the front\n",
    "\texcept:\n",
    "\t\tprint('Skipped')\n",
    " # scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "x_train, y_train = data, labels\n",
    "\n",
    "print('finished running1')\n",
    "\n",
    "#Data in np arrays\n",
    "data = []\n",
    "labels = []\n",
    "print('running2')\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(date_base+'/testing')))\n",
    "for imagePath in imagePaths:\n",
    "\t#load the image, pre-process it, and store it in the data list\n",
    "  image = cv2.imread(imagePath)\n",
    "  try:\n",
    "    image = cv2.resize(image,(28,28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\t\t# extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-1]\n",
    "    labels.append(label[0]) #strips the number label from the front\n",
    "  except:\n",
    "    print('Skipped')\n",
    " # scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "x_test, y_test = data, labels\n",
    "\n",
    "# Normalizing the input image\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "#Converting labels to categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPi9y5mEaEjM"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ot9OPyevaHFx"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "1mFEvY9raDsa",
    "outputId": "f3a879b4-7a58-47d2-de0c-52a4357262dd"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "\n",
    "class CNN:\n",
    "  @staticmethod\n",
    "  def build():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',input_shape=(128,128,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,kernel_regularizer=l2(0.01)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(class_names)))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "CNN_Model = CNN.build()\n",
    "CNN_Model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = CNN_Model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=160, #5097 images/batches of 128 = ~160\n",
    "    epochs=30, \n",
    "    validation_data= test_generator, \n",
    "    validation_steps=33,#1063 images/batchest of 32= 33\n",
    "    verbose=1 #how much to display when training occurs.@2, hides epoch progress\n",
    ")\n",
    "\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrfqh9qnaIoj"
   },
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "880/880 [==============================] - 168s 191ms/step - loss: 1.2495 - acc: 0.5386 - val_loss: 0.8902 - val_acc: 0.6804\n",
      "Epoch 2/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.7275 - acc: 0.7348 - val_loss: 0.8035 - val_acc: 0.7142\n",
      "Epoch 3/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.5630 - acc: 0.7940 - val_loss: 0.8133 - val_acc: 0.7217\n",
      "Epoch 4/50\n",
      "880/880 [==============================] - 154s 175ms/step - loss: 0.4283 - acc: 0.8436 - val_loss: 0.8678 - val_acc: 0.7186\n",
      "Epoch 5/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.3397 - acc: 0.8735 - val_loss: 1.0005 - val_acc: 0.7132\n",
      "Epoch 6/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.2697 - acc: 0.9026 - val_loss: 0.9208 - val_acc: 0.7389\n",
      "Epoch 7/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.2037 - acc: 0.9265 - val_loss: 1.1361 - val_acc: 0.7219\n",
      "Epoch 8/50\n",
      "880/880 [==============================] - 154s 175ms/step - loss: 0.1631 - acc: 0.9432 - val_loss: 1.5474 - val_acc: 0.6595\n",
      "Epoch 9/50\n",
      "880/880 [==============================] - 153s 173ms/step - loss: 0.1323 - acc: 0.9547 - val_loss: 1.1370 - val_acc: 0.7380\n",
      "Epoch 10/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0885 - acc: 0.9724 - val_loss: 1.0803 - val_acc: 0.7466\n",
      "Epoch 11/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0436 - acc: 0.9877 - val_loss: 1.1399 - val_acc: 0.7398\n",
      "Epoch 12/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0376 - acc: 0.9890 - val_loss: 1.0961 - val_acc: 0.7483\n",
      "Epoch 13/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0338 - acc: 0.9903 - val_loss: 1.1568 - val_acc: 0.7436\n",
      "Epoch 14/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0315 - acc: 0.9907 - val_loss: 1.1225 - val_acc: 0.7526\n",
      "Epoch 15/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0298 - acc: 0.9914 - val_loss: 1.1690 - val_acc: 0.7479\n",
      "Epoch 16/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0267 - acc: 0.9920 - val_loss: 1.1446 - val_acc: 0.7524\n",
      "Epoch 17/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0266 - acc: 0.9918 - val_loss: 1.1725 - val_acc: 0.7514\n",
      "Epoch 18/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0240 - acc: 0.9931 - val_loss: 1.2109 - val_acc: 0.7491\n",
      "Epoch 19/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0222 - acc: 0.9936 - val_loss: 1.1799 - val_acc: 0.7516\n",
      "Epoch 20/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0222 - acc: 0.9934 - val_loss: 1.2517 - val_acc: 0.7427\n",
      "Epoch 21/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0216 - acc: 0.9939 - val_loss: 1.2008 - val_acc: 0.7573\n",
      "Epoch 22/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0210 - acc: 0.9940 - val_loss: 1.2245 - val_acc: 0.7513\n",
      "Epoch 23/50\n",
      "880/880 [==============================] - 153s 173ms/step - loss: 0.0191 - acc: 0.9945 - val_loss: 1.2320 - val_acc: 0.7522\n",
      "Epoch 24/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0189 - acc: 0.9945 - val_loss: 1.2402 - val_acc: 0.7560\n",
      "Epoch 25/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 1.2363 - val_acc: 0.7526\n",
      "Epoch 26/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0178 - acc: 0.9946 - val_loss: 1.3199 - val_acc: 0.7470\n",
      "Epoch 27/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 1.2755 - val_acc: 0.7479\n",
      "Epoch 28/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0171 - acc: 0.9947 - val_loss: 1.3242 - val_acc: 0.7510\n",
      "Epoch 29/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0153 - acc: 0.9951 - val_loss: 1.2706 - val_acc: 0.7556\n",
      "Epoch 30/50\n",
      "880/880 [==============================] - 153s 173ms/step - loss: 0.0160 - acc: 0.9952 - val_loss: 1.2871 - val_acc: 0.7571\n",
      "Epoch 31/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0150 - acc: 0.9955 - val_loss: 1.3155 - val_acc: 0.7546\n",
      "Epoch 32/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0144 - acc: 0.9955 - val_loss: 1.3657 - val_acc: 0.7503\n",
      "Epoch 33/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 1.2868 - val_acc: 0.7540\n",
      "Epoch 34/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0129 - acc: 0.9962 - val_loss: 1.4256 - val_acc: 0.7403\n",
      "Epoch 35/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0131 - acc: 0.9961 - val_loss: 1.3500 - val_acc: 0.7511\n",
      "Epoch 36/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 1.3389 - val_acc: 0.7511\n",
      "Epoch 37/50\n",
      "880/880 [==============================] - 152s 172ms/step - loss: 0.0137 - acc: 0.9959 - val_loss: 1.3527 - val_acc: 0.7568\n",
      "Epoch 38/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0126 - acc: 0.9958 - val_loss: 1.3798 - val_acc: 0.7484\n",
      "Epoch 39/50\n",
      "880/880 [==============================] - 152s 172ms/step - loss: 0.0121 - acc: 0.9961 - val_loss: 1.4054 - val_acc: 0.7517\n",
      "Epoch 40/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0124 - acc: 0.9956 - val_loss: 1.3904 - val_acc: 0.7486\n",
      "Epoch 41/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0124 - acc: 0.9961 - val_loss: 1.3998 - val_acc: 0.7541\n",
      "Epoch 42/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0112 - acc: 0.9966 - val_loss: 1.4218 - val_acc: 0.7456\n",
      "Epoch 43/50\n",
      "880/880 [==============================] - 153s 174ms/step - loss: 0.0117 - acc: 0.9964 - val_loss: 1.3429 - val_acc: 0.7643\n",
      "Epoch 44/50\n",
      "880/880 [==============================] - 152s 172ms/step - loss: 0.0117 - acc: 0.9967 - val_loss: 1.4326 - val_acc: 0.7479\n",
      "Epoch 45/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0114 - acc: 0.9961 - val_loss: 1.4684 - val_acc: 0.7517\n",
      "Epoch 46/50\n",
      "880/880 [==============================] - 151s 172ms/step - loss: 0.0100 - acc: 0.9971 - val_loss: 1.4529 - val_acc: 0.7483\n",
      "Epoch 47/50\n",
      "880/880 [==============================] - 152s 173ms/step - loss: 0.0106 - acc: 0.9962 - val_loss: 1.4195 - val_acc: 0.7513\n",
      "Epoch 48/50\n",
      "880/880 [==============================] - 151s 172ms/step - loss: 0.0114 - acc: 0.9960 - val_loss: 1.4992 - val_acc: 0.7441\n",
      "Epoch 49/50\n",
      "880/880 [==============================] - 152s 172ms/step - loss: 0.0105 - acc: 0.9964 - val_loss: 1.4193 - val_acc: 0.7520\n",
      "Epoch 50/50\n",
      "880/880 [==============================] - 152s 172ms/step - loss: 0.0105 - acc: 0.9963 - val_loss: 1.4774 - val_acc: 0.7521\n"
     ]
    }
   ],
   "source": [
    "#importing other required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.applications import VGG19, VGG16, ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Activation,Dropout\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#Defining the hyperparameters\n",
    "batch_size= 100\n",
    "epochs=50\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01,  patience=3, min_lr=1e-5)\n",
    "base_model_VGG19 = VGG19(include_top=False, weights='imagenet', input_shape=(128,128,3), classes=y_train.shape[1])\n",
    "class VGG19:\n",
    "        @staticmethod\n",
    "        def build():\n",
    "            model = Sequential()\n",
    "            model.add(base_model_VGG19) \n",
    "            model.add(Flatten()) \n",
    "            model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
    "            model.add(Dense(512,activation=('relu'))) \n",
    "            model.add(Dense(256,activation=('relu'))) \n",
    "            #model_vgg19.add(Dropout(.3))\n",
    "            model.add(Dense(128,activation=('relu')))\n",
    "            #model_vgg19.add(Dropout(.2))\n",
    "            model.add(Dense(10,activation=('softmax')))\n",
    "            return model\n",
    "\n",
    "#Compiling the VGG19 model\n",
    "VGG19_model = VGG19.build()\n",
    "VGG19_model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = VGG19_model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=880, #1024 images/batches of 128 = 8\n",
    "    epochs=50, \n",
    "    validation_data= test_generator, \n",
    "    validation_steps=219, #256 images/batchest of 32 = 8\n",
    "    callbacks = [lrr],\n",
    "    verbose=1 #how much to display when training occurs.@2, hides epoch progress\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyDNB0ldlvom"
   },
   "source": [
    "### Plotting Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rs9S4MCplu2E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f322d50eeb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = history.history['acc']\n",
    "validation_acc = history.history['val_acc']\n",
    "epochs = range(1,EPOCHS+1)\n",
    "plt.plot(epochs,train_acc,'bo',label='Training Accuracy')\n",
    "plt.plot(epochs,validation_acc,'b',label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnUg64-eaxOi"
   },
   "source": [
    "# Upload and Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aUYIAhRAawO-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(128, 128))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  imgplot = plt.imshow(img)\n",
    "  plt.show() \n",
    "  images = np.vstack([x])\n",
    "  classes = CNN_Model.predict(images, batch_size=1)\n",
    "  print(type(classes))\n",
    "  index_min = np.argmin(classes)\n",
    "  print(fn + f\" is a {class_names[index_min]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "animal_using_datagenerator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python36864bitbaseconda5f2a6790dbda41f0a211fc9e594bb2a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
